{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning PyTorch with Examples (2)\n",
    "\n",
    "Codes are identical to: [pytorch tutorial](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: nn\n",
    "\n",
    "`nn` package provides higher level abstractions: layers, common loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 596.638671875\n",
      "20 191.3060302734375\n",
      "40 63.37615203857422\n",
      "60 21.443504333496094\n",
      "80 7.837594985961914\n",
      "100 3.039156436920166\n",
      "120 1.230210304260254\n",
      "140 0.5139384269714355\n",
      "160 0.222162127494812\n",
      "180 0.09935349225997925\n",
      "200 0.04575412720441818\n",
      "220 0.02160056121647358\n",
      "240 0.010423238389194012\n",
      "260 0.005140047520399094\n",
      "280 0.0025885088834911585\n",
      "300 0.0013219524407759309\n",
      "320 0.0006835238891653717\n",
      "340 0.0003575181763153523\n",
      "360 0.0001888629049062729\n",
      "380 0.00010066367394756526\n",
      "400 5.407274147728458e-05\n",
      "420 2.9255164918140508e-05\n",
      "440 1.5925021216389723e-05\n",
      "460 8.719014658709057e-06\n",
      "480 4.798503141500987e-06\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "N = 64\n",
    "D_in, H, D_out = 1000, 100, 10\n",
    "\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out)\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 20 == 0: print(t, loss.item())\n",
    "    \n",
    "    # reset gradients\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # update parameters (weights)\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: optim\n",
    "\n",
    "`optim` package provides optimization algorithms, like RMSProp, Adam.\n",
    "\n",
    "We now don't need to manually update parameters using gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 671.2236938476562\n",
      "20 410.0433044433594\n",
      "40 255.60887145996094\n",
      "60 157.2102813720703\n",
      "80 92.89498901367188\n",
      "100 52.19229507446289\n",
      "120 27.536178588867188\n",
      "140 13.678248405456543\n",
      "160 6.4642157554626465\n",
      "180 2.898084878921509\n",
      "200 1.2635167837142944\n",
      "220 0.5475822687149048\n",
      "240 0.24350719153881073\n",
      "260 0.11298777908086777\n",
      "280 0.05504155904054642\n",
      "300 0.027734756469726562\n",
      "320 0.014103146269917488\n",
      "340 0.0071294959634542465\n",
      "360 0.0035456218756735325\n",
      "380 0.0017235410632565618\n",
      "400 0.0008161450969055295\n",
      "420 0.0003756010555662215\n",
      "440 0.00016776268603280187\n",
      "460 7.26645375834778e-05\n",
      "480 3.0509087082464248e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "N = 64\n",
    "D_in, H, D_out = 1000, 100, 10\n",
    "\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out)\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate\n",
    ")\n",
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 20 == 0: print(t, loss.item())\n",
    "    \n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    # now we don't update parameters manually!\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: Custom nn Modules\n",
    "\n",
    "For complex nets, you can define it by defining a subclass of `nn.Module`.\n",
    "\n",
    "The `forward` function receives input Tensor, and returns output Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 688.5731811523438\n",
      "20 23.339492797851562\n",
      "40 3.4149560928344727\n",
      "60 0.4524213969707489\n",
      "80 0.054702699184417725\n",
      "100 0.006798021495342255\n",
      "120 0.0008228255901485682\n",
      "140 8.810869621811435e-05\n",
      "160 1.2004516065644566e-05\n",
      "180 1.4686361282656435e-06\n",
      "200 1.8112606881004467e-07\n",
      "220 2.1172434472305213e-08\n",
      "240 2.7380162581636114e-09\n",
      "260 2.997810610860796e-10\n",
      "280 4.1663280464510066e-11\n",
      "300 9.575203477329985e-12\n",
      "320 4.100678130392055e-12\n",
      "340 3.464664319330346e-12\n",
      "360 3.120985241078511e-12\n",
      "380 2.9305527188966396e-12\n",
      "400 2.7256051148699667e-12\n",
      "420 2.401070661739446e-12\n",
      "440 2.947020665694522e-12\n",
      "460 2.4598916653628677e-12\n",
      "480 2.9936728009744007e-12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "    \n",
    "N = 64\n",
    "D_in, H, D_out = 1000, 100, 10\n",
    "\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=learning_rate,\n",
    "    momentum=0.9\n",
    ")\n",
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 20 == 0: print(t, loss.item())\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch: Control Flow + Weight Sharing\n",
    "\n",
    "In here, we will define a network that # of hidden layer changes.\n",
    "(but each layer shares same weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 632.0711669921875\n",
      "20 419.6955871582031\n",
      "40 251.12831115722656\n",
      "60 98.99148559570312\n",
      "80 10.708175659179688\n",
      "100 10.54945182800293\n",
      "120 6.828139781951904\n",
      "140 3.1934988498687744\n",
      "160 3.984523296356201\n",
      "180 1.022364854812622\n",
      "200 11.797147750854492\n",
      "220 10.55497932434082\n",
      "240 11.350359916687012\n",
      "260 3.1293466091156006\n",
      "280 1.3497684001922607\n",
      "300 1.7455763816833496\n",
      "320 0.49634039402008057\n",
      "340 0.6553925275802612\n",
      "360 0.26412442326545715\n",
      "380 0.49488359689712524\n",
      "400 0.6152457594871521\n",
      "420 0.432864785194397\n",
      "440 0.2651008069515228\n",
      "460 0.2529798746109009\n",
      "480 0.34129878878593445\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super().__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "N = 64\n",
    "D_in, H, D_out = 1000, 100, 10\n",
    "\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    momentum=0.9\n",
    ")\n",
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 20 == 0: print(t, loss.item())\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
